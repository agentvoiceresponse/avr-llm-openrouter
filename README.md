# Agent Voice Response - OpenRouter Integration

This repository showcases the integration between **Agent Voice Response** and **OpenRouter**. The application leverages OpenRouter's powerful language model to process text input from users, providing intelligent, context-aware responses that enhance the virtual agent's capabilities.

## Prerequisites

To set up and run this project, you will need:

1. **Node.js** and **npm** installed.
2. An **OpenRouter API key**.

## Setup

### 1. Clone the Repository

```bash
git clone https://github.com/agentvoiceresponse/avr-llm-openrouter.git
cd aavr-llm-openrouter
```

### 2. Install Dependencies

```bash
npm install
```

### 3. Configure Environment Variables

Create a `.env` file in the root of the project to store your API keys and configuration. You will need to add the following variables:

```bash
OPENROUTER_API_KEY=your_openrouter_api_key
OPENROUTER_MODEL=your_openrouter_model
PORT=6002
```

Replace `your_openrouter_api_key` with your actual OpenRouter API key.
Replace `your_openrouter_model` with your preferred model (e.g., "google/gemini-2.0-flash-lite-preview-02-05:free").

### 4. Running the Application

Start the application by running the following command:

```bash
node index.js
```

The server will start on the port defined in the environment variable (default: 6009).

## How It Works

The **Agent Voice Response** system integrates with OpenRouter to provide intelligent text-based responses to user queries. The server receives text input from users, forwards it to OpenRouter's API, and then returns the model's response to the user in real time. This allows the virtual agent to simulate conversational abilities, improving the overall user experience.

### Key Components

- **Express.js Server**: The server handles incoming requests from clients and sends them to OpenRouterâ€™s API for processing.
- **OpenRouter API Integration**: The application sends text queries to OpenRouter and receives generated responses, which are relayed back to the user.
- **Conversation Handling**: The system can maintain the context of conversations for more interactive and dynamic exchanges.

### Example Code Overview

1. **OpenRouter API Request**: The application sends user input to OpenRouter and specifies the model (e.g., `google/gemini-2.0-flash-lite-preview-02-05:free`) to be used for generating responses.
2. **Response Streaming**: The server streams the response back to the client, allowing real-time interaction.
3. **Conversation Context**: You can implement conversation handling by storing previous interactions and passing them as part of the prompt for more contextual responses.

## API Endpoints

### POST `/prompt-stream`

This endpoint accepts a JSON payload containing the user's messages and returns a response generated by OpenRouter.

## Customizing OpenRouter API Requests

In `index.js`, you can modify the parameters sent to OpenRouter, such as changing the model or adjusting the `temperature` and `max_tokens` to control the creativity and length of the responses:

```javascript
const openRouterRequest = {
  model: "gpt-4",
  prompt: query,
  temperature: 0.7,
  max_tokens: 150,
};
```

## Obtaining Your OpenRouter API Key and Selecting a Model

To use this application, you need to obtain an API key from OpenRouter and select a model to use. Follow these steps:

1. Register at OpenRouter: [OpenRouter Registration](https://openrouter.ai)
2. Retrieve your API key from: [OpenRouter API Keys](https://openrouter.ai/settings/keys)
3. Select the model you want to use from: [OpenRouter Models](https://openrouter.ai/models)

Replace `your_openrouter_api_key` and `your_openrouter_model` in the `.env` file with the values you obtained from OpenRouter.
